
本章中，首先描述了以前的GPU是如何工作的，以及GPU与传统CPU的不同之处。描述了GPU是如何针对大量数据进行优化的，通过交换处理器特性，为其他处理器加速单个指令流。\par

描述了GPU如何使用宽SIMD指令并行处理多个数据元素，以及GPU如何使用预测和隐藏延迟来使用SIMD指令执行具有复杂流控制的内核。我们讨论了预测和隐藏延迟如何提高SIMD的效率和内核的性能，以及如何选择在一个维度上并行处理，以减少SIMD的发散。\par

因为GPU有如此多的处理资源，我们讨论了如何给GPU足够的工作来保持高占用率。还描述了GPU如何使用指令流来隐藏延迟，这使得让GPU执行大量工作变得更加重要。\par

接下来，讨论了将内核加载到GPU所涉及的软件和硬件层，以及加载的成本。我们讨论了如何在单个设备上执行算法比在一个设备到另一个设备上执行更有效。\par

最后，描述了在GPU上执行内核时的最佳实践。描述了有多少内核从内存绑定开始，如何有效地访问全局内存和本地内存，如何通过使用子工作组操作来避免使用本地内存。当内核计算绑定时，描述了如何通过用较低的精度换取更高的性能，或使用自定义的GPU扩展来访问专门的指令来优化计算。\par

\hspace*{\fill} \par %插入空行
\textbf{更多信息}

关于GPU编程还有很多需要学习的内容，而这一章只是些皮毛而已!\par

GPU规格和白皮书是学习更多关于特定GPU和GPU架构的好方法。许多GPU供应商提供了关于他们的GPU和如何编程的非常详细的信息。\par

撰写本文时，有关主要图形处理器的相关阅读可以在software.intel.com、devblogs.nvidia.com和amd.com上找到。\par

一些GPU供应商有开源驱动程序或驱动程序组件。在可用的情况下，检查或遍历驱动程序代码，以了解哪些操作是昂贵的，或者应用程序中可能存在哪些开销，可能是有益的。。\par

本章主要讨论通过缓存访问器或统一共享内存对全局内存的传统访问，但大多数GPU也包括一个固定功能的纹理采样器，可以加速对图像的操作。有关图像和采样器的更多信息，请参阅SYCL规范。\par

\newpage